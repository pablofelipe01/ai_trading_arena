# AI Trading Arena Configuration
# This config file defines all system parameters

meta:
  version: "0.1.0"
  phase: "FASE_4_TESTING"
  last_updated: "2025-10-29"
  nof1_compatible: true

trading:
  mode: "paper"  # ALWAYS start with paper!
  capital_per_model: 100.0
  risk:
    max_risk_per_trade: 0.02
    max_position_size: 0.20
    max_daily_loss: 0.05
    enable_circuit_breaker: true
    enable_emergency_stop: true
  execution:
    slippage_simulation: 0.001
    commission_rate: 0.001
    min_order_size_usd: 10.0

exchange:
  name: "binance"
  testnet: true
  symbols:
    # Level 1: AI Trading Basics - 8 major altcoins (NO BTC)
    - "ETH/USDT"   # Ethereum
    - "SOL/USDT"   # Solana
    - "BNB/USDT"   # Binance Coin
    - "ADA/USDT"   # Cardano
    - "XRP/USDT"   # Ripple
    - "DOGE/USDT"  # Dogecoin
    - "POL/USDT"   # Polygon (formerly MATIC)
    - "AVAX/USDT"  # Avalanche
  rate_limits:
    requests_per_minute: 1200
    order_per_second: 10
    weight_per_minute: 6000

data:
  timeframes:
    primary: "3m"
    context:
      - "1m"
      - "15m"
      - "1h"
      - "4h"
  candle_limits:
    "1m": 60
    "3m": 100
    "15m": 96
    "1h": 168
    "4h": 180
  indicators:
    ema:
      periods: [20, 50]
    macd:
      fast: 12
      slow: 26
      signal: 9
    rsi:
      periods: [7, 14]
    atr:
      periods: [3, 14]
    include_volume: true
    include_funding_rate: true
    include_open_interest: true
  cache:
    enabled: true
    ttl_seconds: 60
  ordering: "oldest_to_newest"

prompts:
  template_version: "nof1_exact"
  templates_dir: "strategies/templates"
  enable_ab_testing: false
  max_tokens: 8000
  sections:
    include_market_state: true
    include_price_series: true
    include_indicators: true
    include_funding_rate: true
    include_open_interest: true
    include_recent_performance: true
    include_portfolio_state: true

# LLM Models Configuration
models:
  # DeepSeek - Winner of nof1.ai (+11.06%)
  deepseek:
    enabled: true
    priority: 1  # Highest priority
    api:
      base_url: "https://api.deepseek.com/v1"
      model: "deepseek-chat"
      timeout: 30
    parameters:
      temperature: 0.7
      max_tokens: 2000
      top_p: 0.95
      max_retries: 3
      retry_delay: 2
      max_requests_per_minute: 100
    rate_limit:
      calls_per_minute: 100
    cost:
      input_per_1m_tokens: 0.14
      output_per_1m_tokens: 0.28
    metadata:
      narrative: "Winner of nof1.ai with +11.06% returns"
      color: "#4CAF50"

  # OpenAI GPT-4
  openai:
    enabled: true
    priority: 3
    api:
      base_url: "https://api.openai.com/v1"
      model: "gpt-4o"
      timeout: 30
    parameters:
      temperature: 0.7
      max_tokens: 2000
      top_p: 0.95
      max_retries: 3
      retry_delay: 2
      max_requests_per_minute: 60
    rate_limit:
      calls_per_minute: 60
    cost:
      input_per_1m_tokens: 2.50
      output_per_1m_tokens: 10.00
    metadata:
      narrative: "OpenAI GPT-4o - The industry standard"
      color: "#00A67E"

  # Anthropic Claude
  anthropic:
    enabled: true  # Re-enabled with new API key and correct model
    priority: 4
    api:
      base_url: "https://api.anthropic.com/v1"
      model: "claude-sonnet-4-5-20250929"  # Claude Sonnet 4.5 (current flagship)
      timeout: 60
    parameters:
      temperature: 0.7
      max_tokens: 2000
      top_p: 0.95
      max_retries: 3
      retry_delay: 2
      max_requests_per_minute: 50
    rate_limit:
      calls_per_minute: 50
    cost:
      input_per_1m_tokens: 3.00
      output_per_1m_tokens: 15.00
    metadata:
      narrative: "Claude Sonnet 4.5 - Advanced reasoning"
      color: "#CC785C"

  # Groq (Llama 3.3)
  groq:
    enabled: true
    priority: 2
    api:
      base_url: "https://api.groq.com/openai/v1"
      model: "llama-3.3-70b-versatile"
      timeout: 30
      provider: "groq"
    parameters:
      temperature: 0.7
      max_tokens: 2000
      top_p: 0.95
      max_retries: 3
      retry_delay: 2
      max_requests_per_minute: 120
    rate_limit:
      calls_per_minute: 120
    cost:
      input_per_1m_tokens: 0.0  # Free tier
      output_per_1m_tokens: 0.0
    metadata:
      narrative: "Llama 3.3 via Groq - Ultra-fast inference"
      color: "#F55036"

arena:
  decision_interval: 180  # 3 minutes like nof1.ai (use 5 for quick testing)
  parallel_execution: true
  max_concurrent_llm_calls: 4
  session_duration:
    default: 86400  # 24 hours
    max: 2592000  # 30 days
  leaderboard:
    update_frequency: 300
    metrics:
      - "total_return_pct"
      - "sharpe_ratio"
      - "win_rate"
      - "max_drawdown"
      - "total_trades"
      - "avg_trade_duration"
  persistence:
    save_decisions: true
    save_prompts: true
    save_responses: true
    export_format:
      - "json"
      - "csv"

logging:
  level: "INFO"
  console:
    enabled: true
    colorize: true
    format: "<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan> - <level>{message}</level>"
  file:
    enabled: true
    path: "data/logs/arena.log"
    rotation: "100 MB"
    retention: "30 days"
    compression: "zip"
  structured:
    enabled: true
    path: "data/logs/structured.jsonl"
